---
layout: post
title: "Python爬各医科大学招聘信息"
date: 2019-11-21 10:26:40

tags:
- Python
- 爬虫
- 项目
---
* content
{:toc}

Python爬各医科大学网站上的招聘信息 公司名 手机号 邮箱















### 各文件都是干啥的
1. reg 各大学名和链接，不用改  
2. info_dict.py 字典,主要就改这个  
3. reg2 放json的，测试文件，不用改  
4. test1.py 测试正则能不能匹配到的  
5. core.py 运行的主程序，里面有个大学名得改一下  
6. usual_spider.py 不用改，爬虫的各种类  


### 子页面网址以**?id=4143**结尾,json中能匹配到title和link

1. 复制链接http://fjyk.bibibi.net/module/onlines 到网页中就是列表页，随便点一个进入列表页查看子页面网址，http://hnzyy.bibibi.net/detail/news?id=412244&type_id=128 这样结尾的回到列表页，`Fn+F12`检查元素，随便搜一个列表标题，没有的话就点Network，再搜这个列表标题，啥也没有就刷新网站页面，就会出来一个东西，点这个东西

3. Headers里Request URL对应的就是url，如：http://hnzyy.bibibi.net/module/getonlines?start=0&count=16&k=&professionals=&recruit_type=", "base_url": "http://hnzyy.bibibi.net/detail/online?id= ，复制到test1.py测试一下能不能爬到link(点Reponse就会显示一个json，可以把这个json格式化然后粘贴到一个测试文件reg2里方便看，`Ctrl+F`随便搜一个列表标题，先在test1里复制url链接，用正则匹配到title和link，再复制到字典里)

4. 能爬到的话，复制一块，把名改成你要爬的大学如：福建医科大学，core.py里的名也改喽，上面的链接粘贴到url

5. base_url就是随便点一个列表页进去查看子页面网址，固定的部分如：http://hnzyy.bibibi.net/detail/online?id=

6. 字典如下
	```python
	"湖南中医药大学": {
        "url": "http://hnzyy.bibibi.net/module/getonlines?start=0&count=16&k=&professionals=&recruit_type=",
        "base_url": "http://hnzyy.bibibi.net/detail/online?id=",
        "find_pattern_dict": {
            "title": "\"title\":\"(.*?)\"",
            "link": "\"recruitment_id\":\"(.*?)\"",
        },
    },
	```

7. 正则一样的可以放到模板里，然后`"find_pattern_dict": template3`就行了
	```python
template3 = {
                "title": "title=\"(.*?)\" class=\"item-link",
                "link": "href=\"../info(.*?)\" title",
            }
	```

8. 测试代码如下
	```python
	from requests import get
	from re import findall
	def get_single_page_html(url):
	    resp = get(url)
	    try:
	        resp = resp.content.decode("utf-8")
	    except:
	        try:
	            resp = resp.content.decode("gb2312")
	        except:
	            resp = resp.content.decode("gbk")
	    return resp
	url = 'http://job.kmmc.cn/module/getonlines?start=0&count=16&k=&professionals=&recruit_type='
	resp = get_single_page_html(url)
	patt = "\"link\":\"(.*?)\""
	res = findall(patt,resp)
	print(res)
	```

### 查看源代码就有title和link的
1. `Fn+F12`检查元素，随便搜一个列表标题，没有的话就点Network，Headers里Request URL对应的就是url

2. 点开几个列表页寻找地址共同部分就是base_url

3. 先测试抓取到网页源代码，修改base_url即可，它就是字典中的url
	```python
	#恋爱三部曲
	from urllib import request
	#1.物色对象(确定url的目标)
	base_url = 'http://jy.sxtcm.edu.cn/jyxx/qyzpxx.htm'
	#2.下手攻击(发送请求,GET方式请求,byes)构造一个user_agent
	header = {
	    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'
	}
	response = request.Request(base_url,headers=header)
	newspon = request.urlopen(response)
	#3.等待回复嘿嘿嘿(读取响应数据)
	result = newspon.read()
	#.转化成为utf-8的编码格式
	result = result.decode('utf8')
	#把爬取到的数据写入文件(第一个参数是文件名,第二个参数是写入权限,第三个参数是设置字符集) as of打开一个对象
	with open('test.html','w',encoding="utf-8") as of:
	    of.write(result)
	```

4. 测试正则，注意正则一定要严谨，不要匹配到多余的东西，可以看一下title和link个数是否一样
	```python
	import re
	html = '''
		<li class="item">
	        <div class="item-text">
	            <a href="../info/1054/3460.htm" title="2019太原市妇幼保健院招聘岗位表" class="item-link has-dot">
	                <span class="dot"></span>[企业招聘信息] 2019太原市妇幼保健院招聘岗位表</a>  
	        </div> <span class="item-time">2019-11-20</span>
	    </li>
	'''
	t = re.compile("title=\"(.*?)\" class=\"item-link")
	l = re.compile("href=\"../info(.*?)\" title")
	tt = t.findall(html)
	print(tt,len(tt))
	ll = l.findall(html)
	print(ll,len(ll))
	```

5. 也可以在一个文件中测试
	```python
	from requests import get
	from re import findall
	def get_single_page_html(url):
	    head = {
	    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36',
	}
	    resp = get(url,headers=head)
	    print(resp)
	    try:
	        resp = resp.content.decode("utf-8")
	    except:
	        try:
	            resp = resp.content.decode("gb2312")
	        except:
	            resp = resp.content.decode("gbk")
	    # finally:
	    #     print(resp)
	    # print(resp)
	    return resp
	url = 'http://jy.sxtcm.edu.cn/jyxx/qyzpxx.htm'
	resp = get_single_page_html(url)
	print(resp)
	t = "title=\"(.*?)\" class=\"item-link"
	l = "href=\"../info(.*?)\" title"
	tt = findall(t,resp)
	ll = findall(l,resp)
	print(tt,len(tt))
	print(ll,len(ll))
	```

6. 都测试成功了粘贴到字典中，结果如下
	```python
	"山西中医药大学": {
        # http://jy.sxtcm.edu.cn/info/1054/3460.htm
        "url": "http://jy.sxtcm.edu.cn/jyxx/qyzpxx.htm",
        "base_url": "http://jy.sxtcm.edu.cn/info",
        "find_pattern_dict": {
            "title": "title=\"(.*?)\" class=\"item-link",
            "link": "href=\"../info(.*?)\" title",
        },
    },
	```





